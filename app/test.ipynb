{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"data_resume\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_langchain_db\",  # Where to save data locally, remove if not necessary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_chroma\n",
      "  Downloading langchain_chroma-0.2.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain_chroma) (0.2.43)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.2 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain_chroma) (1.26.4)\n",
      "Requirement already satisfied: chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain_chroma) (0.4.24)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.2.2.post1)\n",
      "Requirement already satisfied: requests>=2.28 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (2.31.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (2.9.2)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.7.3)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.115.5)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.32.1)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (3.7.4)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (4.12.2)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (3.5.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.19.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.28.2)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.28.2)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.49b2)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.28.2)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.21.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (4.66.4)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (6.4.5)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.71.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (4.2.1)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.14.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (31.0.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (8.3.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (6.0.1)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (4.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (3.10.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain_chroma) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain_chroma) (0.1.137)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain_chroma) (23.2)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from build>=1.0.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\shubham\\appdata\\roaming\\python\\python312\\site-packages (from build>=1.0.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.4.6)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fastapi>=0.95.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.41.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain_chroma) (2.4)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (2024.2.2)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\shubham\\appdata\\roaming\\python\\python312\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\shubham\\appdata\\roaming\\python\\python312\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (2.36.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (2.2.1)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.9)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.2.0,>=0.1.112->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain_chroma) (0.27.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.2.0,>=0.1.112->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain_chroma) (1.0.0)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (24.3.25)\n",
      "Requirement already satisfied: protobuf in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (5.27.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.13.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.2.15)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (8.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.66.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.28.2 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.28.2)\n",
      "Requirement already satisfied: opentelemetry-proto==1.28.2 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.28.2)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.49b2 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.49b2)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.49b2 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.49b2)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b2 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.49b2)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.49b2 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.49b2)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-instrumentation==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.17.0)\n",
      "Requirement already satisfied: asgiref~=3.0 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from posthog>=2.4.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from posthog>=2.4.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic>=1.9->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic>=1.9->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.28->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.28->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (3.7)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tokenizers>=0.13.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.28.0)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer>=0.9.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer>=0.9.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer>=0.9.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (13.9.4)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.0.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.0.0)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (14.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (4.9)\n",
      "Requirement already satisfied: anyio in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain_chroma) (4.3.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain_chroma) (1.0.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain_chroma) (1.3.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (2024.10.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (3.21.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\shubham\\appdata\\roaming\\python\\python312\\site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (2.18.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (3.5.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\shubham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.6.1)\n",
      "Downloading langchain_chroma-0.2.2-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: langchain_chroma\n",
      "Successfully installed langchain_chroma-0.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain_chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\SHUBHAM\\Downloads\\Shekhar_Singh_Data_Scientist_Resume.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(file_path)\n",
    "pages = []\n",
    "async for page in loader.alazy_load():\n",
    "    pages.append(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:\\\\Users\\\\SHUBHAM\\\\Downloads\\\\Shekhar_Singh_Data_Scientist_Resume.pdf', 'page': 0}, page_content='8448519835\\nshekhar.singhh9@gmail.com\\nhttps://www.linkedin.com/in/shekhar-\\nsinghh9/\\nPune , Maharastra\\nCONTACT\\nSHEKHAR SINGH\\nDATA SCIENTIST\\nWORK EXPERIENCE\\nEDUCATION\\nCERTIFICATION\\nData Scientist- Intern\\niNeuron\\nConducted data cleaning, pre-processing, and EDA to extract insights from the data.\\nUtilized linear regression model for prediction purposes.\\nDue to a multitude of features, which created the curse of dimensionality, lasso regression\\nwas employed to provide regularization and enhance prediction accuracy.\\nEvaluated model performance using RMSE.\\nMay 2023 - Jul 23\\nBusiness Analyst - Applied AI\\nQuantiphi\\nOct 2021 - Oct 2022\\nSuccessfully delivered project solutions and participated in end-to-end module testing to\\nensure timely and planned system implementation.\\nUtilized SQL (GCP Big Query) to analyze data and identify potential business problem areas,\\nwhich were then presented to clients.\\nConducted data collection, clean-up, and analysis to address daily business needs, establish\\nROI, and estimate project timelines.\\nhttps://github.com/Shekharsittle\\nM.Tech - Mechanical Engineering |\\nIIT(ISM) Dhanbad \\n    \\nB.Tech - Mechanical Engineering |\\nJSS Academy of Technical\\nEducation\\nCGPA - 8.27\\nGATE Percentile - 98.6\\n    \\nPercentage - 74.8\\n    \\nPGP in Data Science and Engineering |\\nGreat Lakes Institute of Management\\nJul 22 - Jul 23\\nGoogle Cloud Platform | Cloud Digital\\nLeader\\nSKILLS\\nPython\\nQdrant\\nLangchain\\nLanggraph\\nDjango Rest Framework\\nAWS\\nMicrosoft Azure\\nOpen AI\\nPytorch\\nTensorflow\\nPandas\\nGCP\\nSQL\\nTableau\\nPower BI\\nMachine Learning\\nDeep Learning\\nFastAPI\\nNLP Scientist- Intern\\nAnalyzed sentiment on a subset of a larger Twitter dataset, unveiling trends, major topics and\\ntheir corresponding sentiments.\\nBuilt several classifier models such as Naive Bayes, Logistic classification, Support Vector\\nMachine and Random Forest, with the logistic classifier achieving an 80% accuracy rate.\\nCreated an RNN model to classify tweets as either negative or positive, with a successful\\naccuracy rate of 77.28%. The model was deployed on Microsoft Azure platform.\\nAug 2023 - Sept  23\\nThe Spark Foundation\\nDATA SCIENTIST\\nSlideoo\\nOct 23 - April 24\\nSuccessfully created an AI feature, including Deck with AI, Web URL to Deck, PDF to Deck, Text\\nto Deck and Youtube to Deck.\\nDeveloped additional customizable features, such as generating outlines and generating deck\\nin different languages, to complement all AI features.\\nImplemented text summarization on pdf documents, web url and youtube data using\\nlangchain.\\nUtilized A100 GPUs to fine-tune the Llama 2 70 b model on our data set on Microsoft Azure.\\nSuccessfully Designed an AI chatbot to assist in creating presentations using the Azure\\nOpenAI API.\\nDATA SCIENTIST\\nPyrack\\nApril 24 - Present\\nDeveloped a vector database using Qdrant for medical resources, including PubMed, VA\\nguidelines, NCCN, and more.\\nCreated an advanced Retrieval-Augmented Generation (RAG) system with LangChain and\\nQdrant Db for the healthcare chatbot aimed at oncologists, incorporating Reciprocal Rank\\nFusion (Hybrid Search) to re-rank documents, which enhanced answer accuracy by 50%.\\nImplemented a AI agent for the Technical Support chatbot, addressing technical queries\\nrelated to the  API integration.\\nIntegrated hallucination checker and language checker agents within LangGraph to boost\\nanswer accuracy.\\nEstablished all backend functionalities for login, signup, and invitation forms for the healthcare\\nweb application using the Django REST framework.\\nDeveloped a data pipeline for scrapping data from various cancer website ,then converting the\\nscrapped text to embeddings and storing it in vector db using chromadb.\\nDeveloped an AI Search for oncologist to get all clinical  trials report and precision medicine\\nfor breast cancer patient.\\nDeployed all code on an AWS EC2 instance and collaborated with DevOps teams to facilitate\\nan automated deployment process utilizing Jenkins.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00f3d5c0-c465-45cb-8e5c-156b127e59c7']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_documents(pages)\n",
    "# vector_store.persist()\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"data_resume\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_langchain_db\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state: State) -> Dict[str, List[Document]]:\n",
    "            \"\"\"Retrieve relevant documents from the vector store\"\"\"\n",
    "            \n",
    "            top_k = state.get(\"top_k\", 3)\n",
    "            retrieved_docs = vector_store.similarity_search(state[\"question\"], k=top_k)\n",
    "            \n",
    "            return {\"context\": retrieved_docs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: chromadb\n",
      "Version: 0.4.24\n",
      "Summary: Chroma.\n",
      "Home-page: https://github.com/chroma-core/chroma\n",
      "Author: \n",
      "Author-email: Jeff Huber <jeff@trychroma.com>, Anton Troynikov <anton@trychroma.com>\n",
      "License: \n",
      "Location: c:\\Users\\SHUBHAM\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\n",
      "Requires: bcrypt, build, chroma-hnswlib, fastapi, grpcio, importlib-resources, kubernetes, mmh3, numpy, onnxruntime, opentelemetry-api, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, opentelemetry-sdk, orjson, overrides, posthog, pulsar-client, pydantic, pypika, PyYAML, requests, tenacity, tokenizers, tqdm, typer, typing-extensions, uvicorn\n",
      "Required-by: langchain-chroma\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8448519835\n",
      "shekhar.singhh9@gmail.com\n",
      "https://www.linkedin.com/in/shekhar-\n",
      "singhh9/\n",
      "Pune , Maharastra\n",
      "CONTACT\n",
      "SHEKHAR SINGH\n",
      "DATA SCIENTIST\n",
      "WORK EXPERIENCE\n",
      "EDUCATION\n",
      "CERTIFICATION\n",
      "Data Scientist- Intern\n",
      "iNeuron\n",
      "Conducted data cleaning, pre-processing, and EDA to extract insights from the data.\n",
      "Utilized linear regression model for prediction purposes.\n",
      "Due to a multitude of features, which created the curse of dimensionality, lasso regression\n",
      "was employed to provide regularization and enhance prediction accuracy.\n",
      "Evaluated model performance using RMSE.\n",
      "May 2023 - Jul 23\n",
      "Business Analyst - Applied AI\n",
      "Quantiphi\n",
      "Oct 2021 - Oct 2022\n",
      "Successfully delivered project solutions and participated in end-to-end module testing to\n",
      "ensure timely and planned system implementation.\n",
      "Utilized SQL (GCP Big Query) to analyze data and identify potential business problem areas,\n",
      "which were then presented to clients.\n",
      "Conducted data collection, clean-up, and analysis to address daily business needs, establish\n",
      "ROI, and estimate project timelines.\n",
      "https://github.com/Shekharsittle\n",
      "M.Tech - Mechanical Engineering |\n",
      "IIT(ISM) Dhanbad \n",
      "    \n",
      "B.Tech - Mechanical Engineering |\n",
      "JSS Academy of Technical\n",
      "Education\n",
      "CGPA - 8.27\n",
      "GATE Percentile - 98.6\n",
      "    \n",
      "Percentage - 74.8\n",
      "    \n",
      "PGP in Data Science and Engineering |\n",
      "Great Lakes Institute of Management\n",
      "Jul 22 - Jul 23\n",
      "Google Cloud Platform | Cloud Digital\n",
      "Leader\n",
      "SKILLS\n",
      "Python\n",
      "Qdrant\n",
      "Langchain\n",
      "Langgraph\n",
      "Django Rest Framework\n",
      "AWS\n",
      "Microsoft Azure\n",
      "Open AI\n",
      "Pytorch\n",
      "Tensorflow\n",
      "Pandas\n",
      "GCP\n",
      "SQL\n",
      "Tableau\n",
      "Power BI\n",
      "Machine Learning\n",
      "Deep Learning\n",
      "FastAPI\n",
      "NLP Scientist- Intern\n",
      "Analyzed sentiment on a subset of a larger Twitter dataset, unveiling trends, major topics and\n",
      "their corresponding sentiments.\n",
      "Built several classifier models such as Naive Bayes, Logistic classification, Support Vector\n",
      "Machine and Random Forest, with the logistic classifier achieving an 80% accuracy rate.\n",
      "Created an RNN model to classify tweets as either negative or positive, with a successful\n",
      "accuracy rate of 77.28%. The model was deployed on Microsoft Azure platform.\n",
      "Aug 2023 - Sept  23\n",
      "The Spark Foundation\n",
      "DATA SCIENTIST\n",
      "Slideoo\n",
      "Oct 23 - April 24\n",
      "Successfully created an AI feature, including Deck with AI, Web URL to Deck, PDF to Deck, Text\n",
      "to Deck and Youtube to Deck.\n",
      "Developed additional customizable features, such as generating outlines and generating deck\n",
      "in different languages, to complement all AI features.\n",
      "Implemented text summarization on pdf documents, web url and youtube data using\n",
      "langchain.\n",
      "Utilized A100 GPUs to fine-tune the Llama 2 70 b model on our data set on Microsoft Azure.\n",
      "Successfully Designed an AI chatbot to assist in creating presentations using the Azure\n",
      "OpenAI API.\n",
      "DATA SCIENTIST\n",
      "Pyrack\n",
      "April 24 - Present\n",
      "Developed a vector database using Qdrant for medical resources, including PubMed, VA\n",
      "guidelines, NCCN, and more.\n",
      "Created an advanced Retrieval-Augmented Generation (RAG) system with LangChain and\n",
      "Qdrant Db for the healthcare chatbot aimed at oncologists, incorporating Reciprocal Rank\n",
      "Fusion (Hybrid Search) to re-rank documents, which enhanced answer accuracy by 50%.\n",
      "Implemented a AI agent for the Technical Support chatbot, addressing technical queries\n",
      "related to the  API integration.\n",
      "Integrated hallucination checker and language checker agents within LangGraph to boost\n",
      "answer accuracy.\n",
      "Established all backend functionalities for login, signup, and invitation forms for the healthcare\n",
      "web application using the Django REST framework.\n",
      "Developed a data pipeline for scrapping data from various cancer website ,then converting the\n",
      "scrapped text to embeddings and storing it in vector db using chromadb.\n",
      "Developed an AI Search for oncologist to get all clinical  trials report and precision medicine\n",
      "for breast cancer patient.\n",
      "Deployed all code on an AWS EC2 instance and collaborated with DevOps teams to facilitate\n",
      "an automated deployment process utilizing Jenkins.\n",
      "Shekhar Singh is a data scientist with experience in developing AI features, data cleaning, and machine learning models. He has worked as an intern at iNeuron and Pyrack, among other roles, and holds an M.Tech in Mechanical Engineering from IIT(ISM) Dhanbad. He specializes in various technologies and programming languages relevant to data science and AI. Thanks for asking!\n"
     ]
    }
   ],
   "source": [
    "question = \"Who is shekhar?\"\n",
    "top_k = 1\n",
    "retrieved_docs = vector_store.similarity_search(question, k=top_k)\n",
    "            \n",
    "print(retrieved_docs[0].page_content)\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Use three sentences maximum and keep the answer as concise as possible.\n",
    "Always say \"thanks for asking!\" at the end of the answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)     \n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            model_provider=\"openai\",\n",
    "            temperature=0.7,\n",
    "            streaming=True\n",
    "        )  \n",
    "docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "                \n",
    "                # Format the prompt\n",
    "prompt_value = prompt.format(\n",
    "                    question=question, \n",
    "                    context=docs_content\n",
    "                )\n",
    "                \n",
    "                # Generate the response\n",
    "response = llm.invoke(prompt_value)    \n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store._collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHUBHAM\\AppData\\Local\\Temp\\ipykernel_17108\\3706075402.py:3: LangChainBetaWarning: The function `init_chat_model` is in beta. It is actively being worked on, so the API may change.\n",
      "  llm = init_chat_model(\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The name of the person in the resume is Shekhar Singh. Thanks for asking!\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.post(\n",
    "    'http://localhost:8000/query',\n",
    "    json={\"query\": \"What is RAG?\", \"top_k\": 3},\n",
    "    stream=True  # Enable streaming\n",
    ")\n",
    "\n",
    "# Read the response chunks as they arrive\n",
    "for chunk in response.iter_content(chunk_size=None, decode_unicode=True):\n",
    "    if chunk:\n",
    "        print(chunk, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langgraph\n",
      "Version: 0.1.5\n",
      "Summary: Building stateful, multi-actor applications with LLMs\n",
      "Home-page: https://www.github.com/langchain-ai/langgraph\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: c:\\Users\\SHUBHAM\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\n",
      "Requires: langchain-core\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph,END\n",
    "from typing_extensions import List, TypedDict\n",
    "from langgraph.checkpoint.memory import MemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state: State) -> Dict[str, List[Document]]:\n",
    "    \"\"\"Retrieve relevant documents from the vector store\"\"\"\n",
    "    \n",
    "    # top_k = state.get(\"top_k\",1)\n",
    "    top_k = 1 \n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"], k=top_k)\n",
    "  \n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "def generate(state: State) -> Dict[str, Any]:\n",
    "    \"\"\"Generate answer using the LLM based on the question and retrieved context\"\"\"\n",
    "    try:\n",
    "        # Log the generation process\n",
    "        logger.info(f\"Generating answer for question: {state['question']}\")\n",
    "        \n",
    "        # Check if context exists\n",
    "        if not state.get(\"context\"):\n",
    "            logger.warning(\"No context available for generating answer\")\n",
    "            return {\"answer\": \"I'm sorry, but I couldn't find any relevant context to answer the question.\"}\n",
    "        \n",
    "        # Combine document contents\n",
    "        docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "        \n",
    "        # Format the prompt\n",
    "        prompt_value = prompt.format(\n",
    "            question=state[\"question\"], \n",
    "            context=docs_content\n",
    "        )\n",
    "        \n",
    "        # Generate the response\n",
    "        response = llm.invoke(prompt_value)\n",
    "        \n",
    "        # Return the answer\n",
    "        return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "memory = MemorySaver()\n",
    "# Compile application and test\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"retrieve\", retrieve)\n",
    "graph_builder.add_node(\"generate\", generate)\n",
    "        \n",
    "        # Define the flow\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph_builder.add_edge(\"retrieve\", \"generate\")\n",
    "graph_builder.add_edge(\"generate\",END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
